# ============================================================
# CONFIGURATION LÉA — Agent IA Droit Numérique
# 1. Copier ce fichier : cp .env.example .env
# 2. Renseigner les valeurs ci-dessous
# 3. Ne JAMAIS commiter le fichier .env
# ============================================================

# Modèle LLM Ollama (local, aucune API externe)
# Options recommandées : mistral, llama3, gemma
LLM_MODEL=mistral

# Modèle d'embeddings Ollama (pour la base vectorielle)
EMBEDDING_MODEL=nomic-embed-text

# URL du service Ollama (ne pas modifier sauf installation custom)
OLLAMA_BASE_URL=http://localhost:11434

# Nombre de chunks retournés par la recherche vectorielle
TOP_K_RESULTS=5

# Taille des chunks de texte (en caractères)
CHUNK_SIZE=500
CHUNK_OVERLAP=50

# Seuil de similarité pour le RAG adaptatif (0.0 à 1.0)
SIMILARITY_THRESHOLD=0.75

# Délai entre les requêtes de scraping (secondes)
# Minimum recommandé : 3 pour respecter les serveurs officiels
SCRAPE_DELAY=3
